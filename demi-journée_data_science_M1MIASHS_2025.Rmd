---
title: "Demi-journée Data Science :
Evaluation des méthodes de sélection de variable
  (Protocole de simulation)."
author: ''
date: "M1 MIASHS 2025"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Un problème essentiel de la régression linéaire multiple est le choix des variables explicatives à conserver.

-   Sélectionner un sous-ensemble de variables permet notamment de réaliser un compromis entre biais et variance.

-   Cela représente également une solution intéressante en cas de multi-colinéarité.

Le choix de modèle dépend des objectifs de la régression (description des données, estimation des paramètres, prévision de nouvelles valeurs) et de la connaissance des données.

## 1. Protocole de simulation

La simulation de données permet d'étudier les propriétés des méthodes dans un cadre parfaitement contrôlé, et d'identifier leurs limites. Afin de préciser les propriétés d'intérêt, il est nécessaire de ce donner un cadre d'étude.

Nous allons mettre au point un protocole de simularion permettant d'**étudier la performance de 3 méthodes de sélection de variables** dans le modèle linéaire :

-   **Test de Student** de signification des coefficients

-   **Recherche exhaustive** (Best subset avec l'algorithme Leaps and bound)

-   **Algorithme de sélection pas à pas** (stepwise)

### 1.1 Cadre d’étude : sélection de variables dans le modèle linéaire

Pour une méthode de sélection de variables, les propriétés d'intérêt sont

-   la capacité à retrouver les variables pertinentes,

-   la capacité à prédire une nouvelle observation,

-   la précision de l'estimation.

La notion de cadre contrôlé se réfère aux hypothèses qui sont faites lors de la définition du modèle statistique.

**Un intérêt important des simulations numériques est de se placer dans le \`\`bon cas" (i.e. celui prévu par la théorie) afin d'étudier les propriétés de la méthode dans ce cadre : on s'assure que les performances sont conformes à celles attendues. On peut ensuite se permettre de s'éloigner du cadre bien contrôlé par la théorie afin d'étudier la robustesse des méthodes évaluées en présence d'écarts aux hypothèses.**

On s'attache ici au modèle linéaire gaussien homoscédastique :

$$Y = X \beta^{\star} + \varepsilon \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (1)$$

avec $Y = (y_1, . . . , y_n)$ un vecteur de $\mathbb{R}^n$, $X$ une matrice de $\mathcal{M}_{n,p}(\mathbb{R})$, $\beta^{\star}=(\beta_1, \ldots , \beta_p)$ un vecteur de $\mathbb{R}^p$ dont $p_0$ éléments sont non-nuls et $\varepsilon \sim \mathcal{N}(0, \Sigma)$ un vecteur gaussien de taille $n$.

On note $S^{\star} = \{j \ \vert \ \beta_j^{\star} \not= 0\}$ l'ensemble de ces éléments, aussi appelé le **support**.

On suppose que les prédicteurs $X$ sont gaussiens multivariés de matrice de variance-covariance $\Sigma_X$.

### 1.2 Contrôle de la difficulté

Lors de l'analyse d'une procédure statistique, il est important de pouvoir contr\^oler précisément la difficulté du problème pour déterminer le champs d'applicabilité de cette méthode. **Ceci permet en particulier de mesurer sa robustesse aux écarts aux hypothèses requit par l'analyse théorique.**

Dans le cadre de la sélection de variables pour le modèle linéaire, divers phénomènes sont associés à la difficulté du problème.

On étudiera en particulier :

-   le niveau de bruit (variance de $\varepsilon$)

-   la structure de dépendance entre les prédicteurs, i.e., la covariance du vecteur $X = (X_1, . . . ,X_p)$.

-   le nombre total de prédicteurs considérés ($p$), le nombre d'observations ($n$) et le ratio $p$/$n$.

On propose dans la suite d'intégrer ces divers paramètres à une fonction que l'on nommera `generate_lm()` permettant de générer des données issues du modèle linéaire (1).

## 2. Mise en oeuvre

### 2.1 Modèle linéaire (cas simple)

Dans un premier temps, les prédicteurs sont tirés selon des distributions gaussiennes univariées indépendantes et de variance unitaire ($\Sigma_X = I_p$).

Ecrire une fonction `generate_lm(n,p,p0,sigma2)` qui renvoie une liste contenant un vecteur y, une matrice x, un vecteur beta (dont p0 éléments non nuls, de magnitude choisie selon une loi uniforme entre 1 et 2 et de signe positif ou négatif).

```{r}
generate.lm <- function(n, p, p0, sigma2, seed = 123) {
  # ------------------------------------------------------------
  # Simulation du modèle linéaire gaussien homoscédastique :
  # Y = X * beta + epsilon
  # ------------------------------------------------------------
  # n      : nombre d'observations
  # p      : nombre total de prédicteurs
  # p0     : nombre de coefficients non nuls (variables pertinentes)
  # sigma2 : variance du bruit
  # seed   : graine aléatoire pour reproductibilité
  
  # Fixer la graine pour rendre les tirages reproductibles
  set.seed(seed)
  
  # 1. Génération des coefficients beta
  beta <- rep(0, p)
  # Choisir aléatoirement p0 positions non nulles
  S_star <- sample(1:p, p0)
  # Coefficients non nuls tirés uniformément entre 1 et 2 et avec signe aléatoire
  beta[S_star] <- runif(p0, 1, 2) * sample(c(-1, 1), p0, replace = TRUE)
  
  # 2. Génération de la matrice des prédicteurs X (indépendants, variance unitaire)
  sigmaMatrix <- diag(p)  # matrice de variance-covariance = I_p
  X <- MASS::mvrnorm(n = n, mu = rep(0, p), Sigma = sigmaMatrix)
  
  # 3. Génération du bruit
  epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))
  
  # 4. Génération de la variable réponse
  y <- X %*% beta + epsilon
  
  # 5. Sortie sous forme de liste
  list(
    y = y,
    X = X,
    beta = beta,
    sigmaMatrix = sigmaMatrix,
    S_star = S_star
  )
}

# Exemple d'utilisation :
data <- generate.lm(50, 10, 5, 60)

data

```

### 2.2 Structure de dépendance des prédicteurs

Les prédicteurs ont pour l'instant été considérés comme indépendants. On propose de modéliser une forme de dépendance entre prédicteurs à l'aide d'une loi gaussienne multivariée telle que $X \sim \mathcal{N}(0,\Sigma_X)$. Outre le cas indépendant ($\Sigma_X = I_p$), on considèrera **AU CHOIX** l'un des 2 scénarios suivant :

-   une dépendance de type longitudinale : $\Sigma_{ij} = \rho^{|i−j|}$.

-   une dépendance par bloc : soit une partition en $K$ groupes, alors

$$\Sigma_{ij} =\left \{
\begin{eqnarray}
1 && \text{ si } i = j,\\
\rho && \text{ si i et j sont dans le même groupe,}\\
0 && \text{ sinon.}\\
\end{eqnarray}
\right . $$

On remarquera que dans le second cas, la sparsité est définie en terme de nombre K0 de blocs avec rho non nul.

Ecrire une fonction `generate.lm.long(n, p, p0, sigma2, rho)` OU `generate.lm.bloc(n, p, K0, sigma2, rho, K)` adaptée au scénario choisi.

```{r}
# install.packages("mvtnorm") # si pas déjà installé
library(mvtnorm)

# Dépendance longitudinale (AR(1)) : Sigma[i,j] = rho^|i-j|
generate.lm.long <- function(n.train, p, p0, sigma2, rho, n.test = 10 * n.train) {
  stopifnot(n.train > 0, p > 0, p0 >= 0, p0 <= p, sigma2 >= 0)
  stopifnot(is.numeric(rho), abs(rho) < 1)  # pour garantir Σ définie positive
  
  n <- n.train + n.test
  train <- 1:n.train
  test  <- (n.train + 1):n
  
  # 1) Matrice de covariance AR(1)
  idx <- 0:(p - 1)
  sigmaMatrix <- outer(idx, idx, function(i, j) rho^abs(i - j))
  
  # 2) Vrai support et coefficients (|β| ~ U[1,2], signe ±)
  beta <- numeric(p)
  if (p0 > 0) {
    S.star <- sample.int(p, p0, replace = FALSE)
    beta[S.star] <- runif(p0, 1, 2) * sample(c(-1, 1), p0, replace = TRUE)
  }
  
  # 3) Génération de X ~ N(0, Σ) et du bruit ε ~ N(0, sigma2)
  X <- rmvnorm(n, mean = rep(0, p), sigma = sigmaMatrix)
  noise <- rnorm(n, sd = sqrt(sigma2))
  
  # 4) Réponse
  y <- as.vector(X %*% beta + noise)
  
  list(
    y = y,
    X = X,
    beta = beta,
    sigma2 = sigma2,
    sigmaMatrix = sigmaMatrix,
    train = train,
    test = test
  )
}
set.seed(1)
dataset <- generate.lm.long(n.train = 100, p = 20, p0 = 5, sigma2 = 1, rho = 0.6, n.test = 200)

# Vérifs
dim(dataset$X)                 # 300 x 20
sum(dataset$beta != 0)         # 5
round(dataset$sigmaMatrix[1:4,1:4], 3)  # vérifie la structure AR(1)

# Ajustement (sans intercept, X centré autour de 0)
df_tr <- data.frame(y = dataset$y[dataset$train], dataset$X[dataset$train, ])
colnames(df_tr) <- c("y", paste0("x", 1:ncol(dataset$X)))
fit <- lm(y ~ . - 1, data = df_tr)
summary(fit)

# MSE test
Xte <- dataset$X[dataset$test, , drop = FALSE]
yte <- dataset$y[dataset$test]
yhat <- as.vector(Xte %*% coef(fit))
mean((yte - yhat)^2)
```

N.B. : Pour la génération d'un vecteur gaussien multivarié, on utilisera le package `mvtnorm`.

### 2.3 Ensemble test, ensemble d’apprentissage

Afin d'évaluer les performances des estimateurs, il est indispensable de générer des données de test.

Amender les fonctions précédentes de sorte à prendre en argument `n.test` et renvoyer en plus des variables précédentes des ensembles `train` et `test`. On pourra affecter une valeur par défaut à `n.test` dépendant de `n.train`, par exemple `10*n.train` (puisqu'on n'est pas limité ici dans un contexte de simulation, une grande taille d'échantillon test permettra une évaluation plus précise).

**On dispose alors d'une fonction renvoyant une liste contenant les variables (y,x,beta,Sigma,sigma,train,test) qui serviront à la génération de données pour les simulations.**

```{r}
generate.lm <- function(n.train, p, p0, sigma2, n.test = 10 * n.train, rho = 0) {
  
  #Création du jeu test et d'entraînement
  X.train <- rmvnorm(n.train, mean = rep(0, p), sigma = Sigma)
  X.test  <- rmvnorm(n.test, mean = rep(0, p), sigma = Sigma)
  
  #Indice des lignes test et apprentissage
  train <- 1:n.train
  test  <- (n.train + 1):(n.train + n.test)
  list(
    y = c(y.train, y.test),
    X = rbind(X.train, X.test),
    beta = beta,
    sigmaMatrix = Sigma,
    train = train,
    test = test
  )
}
```

### 2.4 Implémentation des méthodes de sélection de modèle

On se propose d'étudier les procédures suivantes :

-   la recherche exhaustive best subsets avec critère Cp, AIC et BIC

-   la régression \`\`stepwise" avec critère AIC et BIC,

On comparera ces procédures dites aux méthodes de référence suivantes :

-   les moindres carrés ordinaires (et test de nullité des coefficients),

-   les moindres carrés oracle (i.e. dans le cas où l'on suppose connaître le vrai support $S^{\star}$).

Ecrire une fonction par estimateur `getBestSubset()`, `getStepwiseAIC()`, `getStepwiseBIC()` qui récupère la valeur de $\hat{\beta}$.

```{r}
#Partie recherche exhaustive : 

library(leaps)
out <- regsubsets(dataset$y ~ . , data=train, 
                  nbest=1, nvmax=10, really.big=FALSE) 
bss <- summary(out) 
bss.size <- as.numeric(rownames(bss$which))
intercept <- lm(dataset$y~ 1, data=train) 
bss.best.rss <-
  c(sum(resid(intercept)^2), tapply(bss$rss, bss.size, min)) 
plot(0:10, bss.best.rss, ylim=c(30, 135), type="b", xlab="subset size", 
     ylab="RSS", col="red2" ) 
points(bss.size, bss$rss, pch=20, col="gray", cex=0.7) 

#RSS

library(leaps) 
out <- regsubsets(dataset$y ~ . , data=train, nbest=100, really.big=TRUE) 
bss <- summary(out)
bss.size <- as.numeric(rownames(bss$which))
intercept <- lm(dataset$y ~ 1, data=train)
bss.best.rss <- c(sum(resid(intercept)^2), tapply(bss$rss , bss.size,
                                                  min))
plot(0:8, bss.best.rss, type="b", 
     xlab="subset size", ylab="RSS", col="red2" ) 
points(bss.size, bss$rss, pch=20, col="gray", cex=0.7)

#C_p

bss.best.cp <- tapply(bss$cp , bss.size, min) 
plot(1:8, bss.best.cp, type="b", xlab="subset size", ylab="Cp", col="red2" ) 
points(bss.size, bss$cp, pch=20, col="gray", cex=0.7)

#BIC

bss.best.bic <- tapply(bss$bic , bss.size,min) 
plot(1:8, bss.best.bic, type="b", xlab="subset size", ylab="BIC",
     col="red2" )
points(bss.size, bss$bic, pch=20, col="gray", cex=0.7)


#M.C.ORACLE

oracle <- function(X, Y, S_star) {
  # Sélection des colonnes correspondant au vrai support S*
  X_S_star <- X[, S_star, drop = FALSE]
  
  # Estimateur des moindres carrés sur ces colonnes
  beta_hat_S <- solve(t(X_S_star) %*% X_S_star, t(X_S_star) %*% Y)
  
  # Recréation du vecteur complet de coefficients (les autres sont à zéro)
  beta_hat <- rep(0, ncol(X))
  beta_hat[S_star] <- beta_hat_S
  
  # Valeur de retour
  return(beta_hat)
}

```

N.B. : Les méthodes seront implémentées à partir de la fonction `regsubset()` du package `leaps` et `step()` du package `MASS`.

## 3 Comparaison des méthodes

### 3.1 Évaluation des performances

On s'intéresse aux performances des méthodes à la fois en terme de capacité prédictive et en terme de sélection de variables (pertinence du support estimé $\hat{S}$ = liste des prédicteurs associés à un coefficient non nul de $\hat{\beta}$.)

On considèrera pour cela les grandeurs suivantes :

-   l'erreur quadratique moyenne de $\hat{\beta}$ (RMSE) sur l'ensemble train,

-   l'erreur moyenne de prédiction calculée sur l'ensemble test,

-   la précision du support estimé $\hat{S}$ (=(TN + TP)/p)

-   la sensibilité de $\hat{S}$ (= TP/(FN + TP))

-   la spécificité de $\hat{S}$ (=TN/(TN + FP))

où TP, FP, TN, FN correspondent respectivement à True Positive, False Positive, True Negative et False Negative.

Ecrire une fonction `getPerformance()` qui calcule tous ces indices pour un estimateur $\hat{\beta}$ donné.

```{r, eval = FALSE}
perf <- function(X_test, y_test, beta, beta.star) {
  
  nzero <- which(beta != 0)
  zero  <- which(beta == 0)
  
  true.nzero <- which(beta.star != 0)
  true.zero  <- which(beta.star == 0)
  
  TP <- sum(nzero %in% true.nzero)
  TN <- sum(zero %in%  true.zero)
  FP <- sum(nzero %in% true.zero)
  FN <- sum(zero %in%  true.nzero)
  
  recall    <- TP/(TP + FN) ## also recall and sensitivity
  specificity   <- TN/(FP + TN) ## specificity
  precision <- TP/(TP + FP) ## also PPR
  recall[TP + FN == 0] <- NA
  specificity[TN + FP == 0] <- NA
  precision[TP + FP == 0] <- NA

  rmse <- sqrt(mean((beta - beta.star)^2, na.rm = TRUE))
  rerr <- sqrt(mean((y_test - X_test %*% beta)^2))
  res <-  round(c(precision,recall,specificity, rmse, rerr),4)
  res[is.nan(res)] <- 0
  names(res) <- c("precision","recall","specificity","rmse", "prediction") 
  res
}

```

### 3.2 Planning de simulations

Créer un script de simulation pour chaque scénario de matrice de covariance des prédicteurs $\Sigma_X$, en commençant par exemple par le cas où les prédicteurs sont générés de façon indépendante.

Chaque simulation doit renvoyer un data.frame de la forme suivante, afin de faciliter le tracé des résultats à l'aide du package `ggplot2`.

```{r}
library(tibble)

res <- tribble(
  ~method,       ~mse, ~err,  ~acc, ~sen, ~spe, ~n.p, ~sigma2, ~simu,
  "bestsubset",   0.3, -0.25, 0.92, 0.9,  0.75, 0.5,   0.75,     1,
  "stepwiseAIC",  1.65, -0.17, 0.92, 0.9,  0.75, 0.5,   0.75,     1,
  "stepwiseBIC",  0.51,  0.07, 0.92, 0.9,  0.75, 0.5,   0.75,     1
)

res
```

Ecrire une fonction `getOneSimu(i)` permettant d'effectuer la simulation numéro i pour toutes les méthodes et pour toutes les valeurs des paramètres de simulation que vous aurez choisis.

```{r, eval = FALSE}
library(tidyverse) # pour l'utilisation du pipe %>%
getOneSimu <- function(i) {
  data <- generate.lm(n.train=100, p=50, p0=10, sigma2=1, n.test=10*n.train100)
  
  beta_AIC <- getStepAIC(data$X[data$train, ], data$y[data$train])
  beta_BIC <- getStepBIC(data$X[data$train, ], data$y[data$train])
  
  res <-
    data.frame(
      rbind(
        perf(data$X[data$test, ], data$y[data$test], beta_AIC, data$beta),
        perf(data$X[data$test, ], data$y[data$test], beta_BIC, data$beta)
      )
    ) %>% 
    add_column(method = c("stepAIC", "stepBIC")) %>% 
    add_column(simu_label = i)
  res
}
```

N.B. Cette fonction sera ensuite facilement parallélisable, par exemple avec le package `parallel` ou `pbmcapply` :

```{r, eval=FALSE}
library(tidyverse) # pour la fonction Reduce()
library(pbmcapply)
n_simu <- 10
res <- Reduce("rbind", pbmclapply(1:n_simu, getOneSimu, mc.cores = 2))

```

### 3.3 Interprétations des résultats

-   Représentez les boxplots des indicateurs de performance en fonction du ratio $p$/$n$ et de la valeur du R2. On utilisera le package `ggplot2`.
-   Quels sont les effets du ratio $p$/$n$ et de la corrélation des prédicteurs sur les performances des estimateurs (en estimation, en sélection) ?
-   Explorer les differents scénarios. Y a t-il des méthodes plus adaptées à certains scénarios ? Si oui, pourquoi ?

```{r}
# ==== 1) Recherche exhaustive (leaps::regsubsets) ====
# crit = "Cp", "AIC", "BIC"
getBestSubset <- function(X, y, crit = c("Cp","AIC","BIC"), nvmax = NULL) {
  crit <- match.arg(crit)
  df <- .make_df(X, y)
  n  <- nrow(df); p <- ncol(df) - 1
  if (is.null(nvmax)) nvmax <- min(p, n - 1) else nvmax <- min(nvmax, p, n - 1)

  out <- leaps::regsubsets(y ~ ., data = df, nbest = 1, nvmax = nvmax, really.big = FALSE)
  bss <- summary(out)

  k   <- rowSums(bss$which)           # nb de paramètres (intercept inclus)
  rss <- bss$rss
  score <- switch(crit,
    "Cp"  = bss$cp,
    "BIC" = bss$bic,
    "AIC" = n * log(rss / n) + 2 * k
  )
  id <- which.min(score)
  .make_beta(coef(out, id = id), colnames(df)[-1])
}

# ==== 2) Stepwise AIC (MASS::stepAIC) ====
getStepwiseAIC <- function(X, y, direction = "both") {
  df <- .make_df(X, y)
  full <- lm(y ~ ., data = df)
  null <- lm(y ~ 1, data = df)
  fit  <- MASS::stepAIC(null, scope = list(lower = null, upper = full),
                        direction = direction, trace = FALSE, k = 2) # AIC
  .make_beta(coef(fit), colnames(df)[-1])
}

# ==== 3) Stepwise BIC (MASS::stepAIC avec k = log(n)) ====
getStepwiseBIC <- function(X, y, direction = "both") {
  df <- .make_df(X, y)
  n  <- nrow(df)
  full <- lm(y ~ ., data = df)
  null <- lm(y ~ 1, data = df)
  fit  <- MASS::stepAIC(null, scope = list(lower = null, upper = full),
                        direction = direction, trace = FALSE, k = log(n)) # BIC
  .make_beta(coef(fit), colnames(df)[-1])
}

# ==== 4) Alias demandé : getStepBIC() ====
# (équivalent à getStepwiseBIC pour respecter la consigne de nommage)
getStepBIC <- function(X, y, direction = "both") {
  getStepwiseBIC(X, y, direction = direction)
}

```
